{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb346df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from kiwipiepy import Kiwi\n",
    "from typing import TypedDict, List, Literal, Any\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_naver import ChatClovaX, ClovaXEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_milvus import Milvus\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatClovaX(\n",
    "    model=\"HCX-DASH-002\", \n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "embeddings = ClovaXEmbeddings(\n",
    "    model=\"bge-m3\",\n",
    "    api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a2c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    }
   ],
   "source": [
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text) if token.tag.startswith('N')]\n",
    "\n",
    "def get_documents_from_milvus(vector_db):\n",
    "    collection = vector_db.col\n",
    "    res = collection.query(\n",
    "        expr=\"\", \n",
    "        output_fields=[\"text\", \"idx\"], \n",
    "        limit=16384\n",
    "    )\n",
    "    \n",
    "    docs = []\n",
    "    for item in res:\n",
    "        text = item.get('text')\n",
    "        idx = item.get('idx') \n",
    "        \n",
    "        if text:\n",
    "            docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"idx\": idx} \n",
    "            ))\n",
    "            \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d979fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualEnsembleRetriever:\n",
    "    def __init__(self, retrievers, weights=None, c=60):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights if weights else [0.5] * len(retrievers)\n",
    "        self.c = c \n",
    "\n",
    "    def invoke(self, query):\n",
    "        results = [r.invoke(query) for r in self.retrievers]\n",
    "        rrf_score = defaultdict(float)\n",
    "        doc_map = {}\n",
    "\n",
    "        for r_idx, docs in enumerate(results):\n",
    "            weight = self.weights[r_idx]\n",
    "            for rank, doc in enumerate(docs):\n",
    "                doc_key = doc.page_content\n",
    "                if doc_key not in doc_map:\n",
    "                    doc_map[doc_key] = doc\n",
    "                \n",
    "                score = weight * (1 / (rank + 1 + self.c))\n",
    "                rrf_score[doc_key] += score\n",
    "\n",
    "        sorted_keys = sorted(rrf_score.keys(), key=lambda k: rrf_score[k], reverse=True)\n",
    "        return [doc_map[k] for k in sorted_keys]\n",
    "\n",
    "\n",
    "def create_hybrid_retriever(vector_db, k=20):\n",
    "    raw_docs = get_documents_from_milvus(vector_db)\n",
    "    vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    if not raw_docs:\n",
    "        return vector_retriever\n",
    "        \n",
    "    bm25_retriever = BM25Retriever.from_documents(\n",
    "        raw_docs, \n",
    "        preprocess_func=kiwi_tokenize\n",
    "    )\n",
    "    bm25_retriever.k = k\n",
    "    \n",
    "    return ManualEnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.5, 0.5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1604d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"title\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "standards_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"standards\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "outline_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"outline\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "problems_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"problems\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "opinion_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"opinion\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "criteria_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"criteria\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "action_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"action\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "retrievers = {\n",
    "    \"title\": create_hybrid_retriever(title_db),\n",
    "    \"standards\": create_hybrid_retriever(standards_db),\n",
    "    \"outline\": create_hybrid_retriever(outline_db),\n",
    "    \"problems\": create_hybrid_retriever(problems_db),\n",
    "    \"opinion\": create_hybrid_retriever(opinion_db),\n",
    "    \"criteria\": create_hybrid_retriever(criteria_db),\n",
    "    \"action\": create_hybrid_retriever(action_db),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4072b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    search_query: str\n",
    "    selected_fields: List[str]\n",
    "    selected_fields_cot: List[str]\n",
    "    documents: List[Any]\n",
    "    is_valid: str\n",
    "    validator_cot: List[str]\n",
    "    analysis_decision: str\n",
    "    strategy_decider_cot: List[str]\n",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960db234",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_selector_system = \"\"\"\n",
    "[역할]\n",
    "당신은 감사 보고서 기반 RAG 시스템의 필드 선택기(Field Selector)입니다.\n",
    "\n",
    "[목표]\n",
    "사용자 질문을 분석하여,\n",
    "아래에 정의된 7개의 필드 중 질문과 직접적으로 관련된 필드를 정확히 선택하십시오.\n",
    "\n",
    "[핵심 원칙]\n",
    "- 모든 판단은 질문의 의미와 의도를 기준으로 수행합니다.\n",
    "- 추측이나 일반적 관행에 근거한 선택은 허용되지 않습니다.\n",
    "- 질문에서 명시적으로 요구되거나 논리적으로 필수적인 필드만 선택합니다.\n",
    "\n",
    "[필수 포함 규칙]\n",
    "- \"outline\"과 \"problems\"는 질문의 유형과 무관하게 항상 포함해야 합니다.\n",
    "\n",
    "[조건부 선택 규칙]\n",
    "- title: 사건명이나 특정 사안의 명칭 자체를 묻는 경우에만 선택합니다.\n",
    "- standards: 법령, 규정, 기준, 위반 여부, 적법성 판단이 질문의 핵심인 경우에만 선택합니다.\n",
    "- opinion: 관계기관의 입장, 해명, 평가, 의견을 묻는 경우에만 선택합니다.\n",
    "- criteria: 개선 방안, 재발 방지 대책, 내부통제 강화, 절차 보완을 묻는 경우에만 선택합니다.\n",
    "- action: 처분, 제재, 징계, 후속 조치의 내용이나 수준을 묻는 경우에만 선택합니다.\n",
    "\n",
    "[선택 가능한 필드 정의]\n",
    "- title: 사건 제목, 사안명\n",
    "- standards: 법령, 규정, 기준, 위반 여부\n",
    "- outline: 사건의 개요, 배경, 전체 상황\n",
    "- problems: 위반 사항, 문제점, 부적정 사례\n",
    "- opinion: 관계기관의 의견, 평가, 입장\n",
    "- criteria: 개선 방안, 내부통제, 절차 보완\n",
    "- action: 처분, 제재, 징계, 후속 조치\n",
    "\n",
    "[출력 형식]\n",
    "- 출력은 반드시 하나의 JSON 객체여야 합니다.\n",
    "- JSON에는 아래 두 개의 키만 포함해야 합니다.\n",
    "\n",
    "{{\n",
    "  \"selected_fields\": [소문자 문자열 리스트],\n",
    "  \"cot\": [\n",
    "    \"Step 1: 질문의 핵심 의도와 요구 정보를 분석한다.\",\n",
    "    \"Step 2: 필수 규칙에 따라 outline과 problems를 포함한다.\",\n",
    "    \"Step 3: 질문의 내용에 따라 추가로 필요한 필드를 판단하여 선택한다.\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "[출력 규칙]\n",
    "- selected_fields에는 항상 \"outline\"과 \"problems\"가 포함되어야 합니다.\n",
    "- selected_fields_cot는 단계적 판단 과정을 나타내는 문자열 리스트여야 합니다.\n",
    "- selected_fields_cot는 최소 3단계 이상 작성해야 합니다.\n",
    "- JSON 외의 텍스트는 절대 출력하지 마십시오.\n",
    "\n",
    "[출력 예시]\n",
    "{{\n",
    "  \"selected_fields\": [\"outline\", \"problems\", \"standards\"],\n",
    "  \"selected_fields_cot\": [\n",
    "    \"Step 1: 질문은 사건에서 법령이나 규정 위반 여부를 확인하려는 목적이다.\",\n",
    "    \"Step 2: 모든 질문에 필수로 포함해야 하는 outline과 problems를 선택한다.\",\n",
    "    \"Step 3: 위반된 법령과 기준 판단이 필요하므로 standards를 추가한다.\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "field_selector_user = \"\"\"\n",
    "[Question]\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "field_selector_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", field_selector_system),\n",
    "    (\"human\", field_selector_user)\n",
    "])\n",
    "\n",
    "field_selector_chain = (\n",
    "    field_selector_template\n",
    "    | llm\n",
    "    | JsonOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "validator_system = \"\"\"\n",
    "[역할]\n",
    "당신은 감사 보고서 검색 결과의 유효성을 판별하는 검증관(Validator)입니다.\n",
    "\n",
    "[목표]\n",
    "사용자의 질문(question)과 검색된 문서(context)를 비교하여,\n",
    "제공된 문서만을 근거로 질문에 대해 직접적인 답변이 가능한지를 판단하십시오.\n",
    "\n",
    "[사고 방식]\n",
    "- 판단은 단계적 사고 과정을 거쳐 수행해야 합니다.\n",
    "- 각 단계는 질문 요구, 문서 확인, 답변 가능성 판단의 흐름의 순서를 따라야 합니다.\n",
    "- 판단 과정은 validator_cot에 반드시 기록해야 합니다.\n",
    "\n",
    "[판단 원칙]\n",
    "- 판단은 오직 제공된 문서(context)에 근거해야 합니다.\n",
    "- 외부 지식, 일반 상식, 추론 보완은 허용되지 않습니다.\n",
    "- 문서에 질문의 핵심 정보가 명시적으로 없으면 반드시 \"no\"로 판단하십시오.\n",
    "- 애매한 경우에는 반드시 \"no\"를 선택하십시오.\n",
    "\n",
    "[출력 형식]\n",
    "출력은 반드시 하나의 JSON 객체여야 하며,\n",
    "아래 두 개의 키만 포함해야 합니다.\n",
    "\n",
    "{{\n",
    "  \"is_valid\": \"yes\" 또는 \"no\",\n",
    "  \"validator_cot\": [\n",
    "    \"Step 1: 질문이 요구하는 핵심 정보와 판단 기준을 식별한다.\",\n",
    "    \"Step 2: 문서에서 해당 정보가 명시적으로 존재하는지 확인한다.\",\n",
    "    \"Step 3: 문서만으로 질문에 직접 답변 가능한지 판단한다.\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "[출력 규칙]\n",
    "- is_valid 값은 반드시 소문자 문자열 \"yes\" 또는 \"no\"만 허용됩니다.\n",
    "- validator_cot는 반드시 단계별 사고 흐름을 나타내는 문자열 리스트여야 합니다.\n",
    "- validator_cot는 최소 3단계 이상 작성해야 합니다.\n",
    "- JSON 외의 텍스트는 절대 출력하지 마십시오.\n",
    "\n",
    "[출력 예시]\n",
    "{{\n",
    "  \"is_valid\": \"no\",\n",
    "  \"validator_cot\": [\n",
    "    \"Step 1: 질문은 출장비 부당 집행 이후 어떤 징계나 처분이 있었는지를 묻고 있다.\",\n",
    "    \"Step 2: 검색된 문서에는 출장비 부당 집행 사례와 문제점은 있으나, 징계나 처분 내용은 명시되어 있지 않다.\",\n",
    "    \"Step 3: 문서 내용만으로는 처분 여부를 답할 수 없으므로 유효하지 않다고 판단했다.\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "validator_user = \"\"\"\n",
    "[Question]\n",
    "{question}\n",
    "\n",
    "[Retrieved Documents]\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "validator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", validator_system),\n",
    "    (\"human\", validator_user)\n",
    "])\n",
    "\n",
    "validator_chain = (\n",
    "    validator_prompt\n",
    "    | llm\n",
    "    | JsonOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "strategy_decider_system = \"\"\"\n",
    "[역할]\n",
    "당신은 검색 실패 원인을 분석하고 다음 행동 전략을 결정하는 전략 결정자(StrategyDecider)입니다.\n",
    "\n",
    "[상황]\n",
    "현재 검색 결과는 검증기(Validator)를 통과하지 못했습니다.\n",
    "당신은 아래 세 가지 정보를 모두 참고하여,\n",
    "다음 단계에서 취할 전략을 하나 선택해야 합니다.\n",
    "\n",
    "- 필드 선택기의 사고 과정(selected_fields_cot)\n",
    "- 현재 선택된 필드 목록(current_fields)\n",
    "- 검증기의 사고 과정(validator_cot)\n",
    "\n",
    "[선택 가능한 전략]\n",
    "1. rewrite_query\n",
    "   - 질문의 핵심 정보 유형은 맞으나, 현재 쿼리는 검색에 적합하지 않은 형태입니다.\n",
    "   - 질문이 종합·판단형으로 작성되어 있어 사례(action)나 처분 결과가 직접 검색되지 않았습니다.\n",
    "   - 쿼리를 사례 조회 중심, 처분·징계 중심의 검색형 문장으로 재작성하면\n",
    "     다른 문서가 검색될 가능성이 높습니다.\n",
    "   - new_query를 실제로 의미 있게 재작성할 수 있는 경우에만 선택해야 합니다.\n",
    "\n",
    "2. update_fields\n",
    "   - selected_fields_cot에서의 판단은 부분적으로 타당했습니다.\n",
    "   - 문서의 주제는 질문과 대체로 일치합니다.\n",
    "   - 그러나 질문이 요구하는 특정 정보 유형(규정, 조치, 기준 등)이 문서에 없습니다.\n",
    "   - 현재 선택되지 않은 다른 필드를 추가하면 답변 가능성이 높아질 것으로 판단됩니다.\n",
    "\n",
    "[선택 가능한 전체 필드 목록]\n",
    "title, outline, problems, standards, criteria, action, opinion\n",
    "\n",
    "[필수 제약 규칙 — 매우 중요]\n",
    "- missing_fields는 반드시 current_fields에 포함되지 않은 필드만 선택해야 합니다.\n",
    "- 이미 선택된 필드를 다시 선택하는 것은 절대 허용되지 않습니다.\n",
    "- current_fields를 제외한 나머지 필드 중에서만 missing_fields를 구성하십시오.\n",
    "- update_fields 전략을 선택했음에도 추가할 필드가 없다면,\n",
    "  반드시 rewrite_query 전략을 선택해야 합니다.\n",
    "- rewrite_query 전략을 선택한 경우,\n",
    "  new_query는 원본 질문과 문장 구조 또는 검색 초점이 반드시 달라야 합니다.\n",
    "- 원본 질문을 그대로 반복하거나 의미만 바꾼 수준의 쿼리는 허용되지 않습니다.\n",
    "\n",
    "[사고 방식]\n",
    "- Step 1에서는 selected_fields_cot를 분석하여,\n",
    "  현재 필드 구성이 질문의 정보 요구에는 적절했는지 판단합니다.\n",
    "- Step 2에서는 validator_cot를 분석하여,\n",
    "  문서에 사례(action) 또는 처분 결과가 존재하지 않았다는 점을 명확히 식별합니다.\n",
    "- Step 3에서는 다음 중 하나를 명확히 결정합니다.\n",
    "  - 필드는 충분하지만, 사례·처분을 직접 검색할 수 있도록 쿼리를 재작성해야 한다.\n",
    "  - 필드 자체가 부족하므로 필드를 확장해야 한다.\n",
    "- 이 판단 과정은 strategy_decider_cot에 구체적인 판단 근거로 기록해야 합니다.\n",
    "\n",
    "[출력 형식 - rewrite_query]\n",
    "출력은 반드시 하나의 JSON 객체여야 하며,\n",
    "아래 네 개의 키만 포함해야 합니다.\n",
    "\n",
    "{{\n",
    "  \"strategy\": \"rewrite_query\",\n",
    "  \"missing_fields\": [],\n",
    "  \"new_query\": \"사례·처분·징계·조치(action)를 직접 검색할 수 있도록 재작성된 검색 쿼리\",\n",
    "  \"strategy_decider_cot\": [\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 1\",\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 2\",\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 3\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "[출력 형식 - update_fields]\n",
    "출력은 반드시 하나의 JSON 객체여야 하며,\n",
    "아래 네 개의 키만 포함해야 합니다.\n",
    "\n",
    "{{\n",
    "  \"strategy\": \"update_fields\",\n",
    "  \"missing_fields\": [\"current_fields에 포함되지 않은 필드명\"],\n",
    "  \"new_query\": \"\",\n",
    "  \"strategy_decider_cot\": [\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 1\",\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 2\",\n",
    "    \"이번 질문과 검색 실패 상황에 근거한 실제 판단 내용 3\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "[출력 규칙]\n",
    "- strategy는 반드시 두 값 중 하나여야 합니다.\n",
    "- update_fields 전략인 경우 new_query는 반드시 빈 문자열 \"\"이어야 합니다.\n",
    "- rewrite_query 전략인 경우 new_query는 반드시 비어 있지 않은 문자열이어야 하며,\n",
    "  사례, 처분, 징계, 조치(action) 중심의 검색형 문장이어야 합니다.\n",
    "- rewrite_query 전략이 아닌 경우 missing_fields는 반드시 빈 리스트 []여야 합니다.\n",
    "- missing_fields에는 current_fields에 포함된 필드가 하나라도 있으면 안 됩니다.\n",
    "- strategy_decider_cot는 최소 3단계 이상 작성해야 합니다.\n",
    "- JSON 외의 텍스트는 절대 출력하지 마십시오.\n",
    "\n",
    "[출력 예시 - rewrite_query]\n",
    "{{\n",
    "  \"strategy\": \"rewrite_query\",\n",
    "  \"missing_fields\": [],\n",
    "  \"new_query\": \"출장비 부당 집행과 관련하여 감사 결과로 실제 내려진 징계 또는 처분 사례\",\n",
    "  \"strategy_decider_cot\": [\n",
    "    \"selected_fields_cot에 따르면 필드 구성은 질문 의도에 부합했으나, 쿼리가 종합 판단형으로 작성되어 사례 검색에 적합하지 않았다.\",\n",
    "    \"validator_cot를 보면 문서에는 출장비 관련 일반적인 개선 사항만 존재하고, 처분 사례는 검색되지 않았다.\",\n",
    "    \"처분 사례를 직접 검색하기 위해 질문을 사례·징계 중심의 검색형 쿼리로 재작성하기로 결정했다.\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "[출력 예시 - update_fields]\n",
    "{{\n",
    "  \"strategy\": \"update_fields\",\n",
    "  \"missing_fields\": [\"action\"],\n",
    "  \"new_query\": \"\",\n",
    "  \"strategy_decider_cot\": [\n",
    "    \"selected_fields_cot에 따르면 사건의 개요와 문제점 중심으로 필드가 선택되어 질문 주제와는 일치했다.\",\n",
    "    \"validator_cot를 확인한 결과 문서에는 문제 상황은 있으나, 실제 처분이나 징계 정보가 포함되어 있지 않았다.\",\n",
    "    \"처분 정보는 현재 필드에 없으므로 action 필드를 추가하는 전략이 필요하다고 판단했다.\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "strategy_decider_user = \"\"\"\n",
    "[Question]\n",
    "{question}\n",
    "\n",
    "[Selected Fields]\n",
    "{current_fields}\n",
    "\n",
    "[Field Selector COT]\n",
    "{selected_fields_cot}\n",
    "\n",
    "[Validator COT]\n",
    "{validator_cot}\n",
    "\"\"\"\n",
    "\n",
    "strategy_decider_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", strategy_decider_system),\n",
    "    (\"human\", strategy_decider_user)\n",
    "])\n",
    "\n",
    "strategy_decider_chain = (\n",
    "    strategy_decider_prompt\n",
    "    | llm\n",
    "    | JsonOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cae4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = CrossEncoder(\"BAAI/bge-reranker-v2-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dccf8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selector(state: GraphState) -> dict:\n",
    "    current_input = state.get(\"search_query\") if state.get(\"search_query\") else state[\"question\"]\n",
    "    \n",
    "    result = field_selector_chain.invoke({\"question\": current_input})\n",
    "\n",
    "    new_selected = result.get(\"selected_fields\", [])\n",
    "    cot = result.get(\"selected_fields_cot\", [])\n",
    "\n",
    "    current_fields = state.get(\"selected_fields\", [])\n",
    "    merged_fields = list(set(current_fields + new_selected))\n",
    "\n",
    "    if \"outline\" not in merged_fields:\n",
    "        merged_fields.append(\"outline\")\n",
    "    if \"problems\" not in merged_fields:\n",
    "        merged_fields.append(\"problems\")\n",
    "\n",
    "    return {\n",
    "        \"selected_fields\": merged_fields,\n",
    "        \"selected_fields_cot\": cot\n",
    "    }\n",
    "\n",
    "\n",
    "def retriever(state: GraphState) -> dict:\n",
    "    search_query = state.get(\"search_query\", state[\"question\"])\n",
    "    original_question = state[\"question\"]\n",
    "    \n",
    "    target_fields = state[\"selected_fields\"]\n",
    "    \n",
    "    selected_retrievers = {\n",
    "        field: RunnableLambda(retrievers[field].invoke) \n",
    "        for field in target_fields\n",
    "    }\n",
    "    \n",
    "    results = RunnableParallel(**selected_retrievers).invoke(search_query)\n",
    "    \n",
    "    grouped_content = defaultdict(list)\n",
    "    for field, docs in results.items():\n",
    "        for doc in docs:\n",
    "            grouped_content[doc.metadata[\"idx\"]].append((field, doc.page_content))\n",
    "\n",
    "    new_docs = []\n",
    "    for idx, contents in grouped_content.items():\n",
    "        contents.sort(key=lambda x: x[0]) \n",
    "        full_text = \"\\n\\n\".join([f\"[{field.upper()}]\\n{text}\" for field, text in contents])\n",
    "        \n",
    "        new_docs.append(Document(\n",
    "            page_content=full_text,\n",
    "            metadata={\"idx\": idx, \"fields\": [c[0] for c in contents]}\n",
    "        ))\n",
    "\n",
    "    previous_docs = state.get(\"documents\", [])\n",
    "    all_docs = previous_docs + new_docs\n",
    "    \n",
    "    unique_docs_map = {doc.metadata[\"idx\"]: doc for doc in all_docs}\n",
    "    unique_docs = list(unique_docs_map.values())\n",
    "    \n",
    "    if not unique_docs:\n",
    "        return {\"documents\": []}\n",
    "\n",
    "    pairs = [[original_question, doc.page_content] for doc in unique_docs]\n",
    "    scores = encoder_model.predict(pairs)\n",
    "    \n",
    "    scored_docs = sorted(zip(unique_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "    top5_docs = [doc for doc, _ in scored_docs[:5]]\n",
    "    \n",
    "    return {\"documents\": top5_docs}\n",
    "\n",
    "\n",
    "def validator(state: GraphState) -> dict:\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    if not documents:\n",
    "        return {\"is_valid\": \"no\", \"validator_cot\": [\"문서 없음\"]}\n",
    "\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    result = validator_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"is_valid\": str(result.get(\"is_valid\", \"no\")).lower().strip(),\n",
    "        \"validator_cot\": result.get(\"validator_cot\", [])\n",
    "    }\n",
    "\n",
    "\n",
    "def strategy_decider(state: GraphState) -> dict:\n",
    "    question = state[\"question\"]\n",
    "    current_fields = state[\"selected_fields\"]\n",
    "    \n",
    "    sel_cot_text = \"\\n\".join(state.get(\"selected_fields_cot\", []))\n",
    "    val_cot_text = \"\\n\".join(state.get(\"validator_cot\", []))\n",
    "    \n",
    "    result = strategy_decider_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"current_fields\": str(current_fields),\n",
    "        \"selected_fields_cot\": sel_cot_text,\n",
    "        \"validator_cot\": val_cot_text\n",
    "    })\n",
    "\n",
    "    strategy = result.get(\"strategy\", \"rewrite_query\")\n",
    "    llm_suggested_missing = result.get(\"missing_fields\", [])\n",
    "    new_query = result.get(\"new_query\", \"\").strip()\n",
    "    decider_cot = result.get(\"strategy_decider_cot\", [])\n",
    "    \n",
    "    final_missing_fields = list(set(llm_suggested_missing) - set(current_fields))\n",
    "    \n",
    "    if strategy == \"update_fields\" and not final_missing_fields:\n",
    "        strategy = \"rewrite_query\"\n",
    "        if not new_query:\n",
    "            new_query = question \n",
    "\n",
    "    updates = {\n",
    "        \"analysis_decision\": strategy,\n",
    "        \"strategy_decider_cot\": decider_cot,\n",
    "        \"retry_count\": state.get(\"retry_count\", 0) + 1\n",
    "    }\n",
    "    \n",
    "    if strategy == \"update_fields\" and final_missing_fields:\n",
    "        new_fields = list(set(current_fields + final_missing_fields))\n",
    "        updates[\"selected_fields\"] = new_fields\n",
    "        \n",
    "    elif strategy == \"rewrite_query\" and new_query:\n",
    "        updates[\"search_query\"] = new_query\n",
    "        \n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99de4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"field_selector\", field_selector)\n",
    "workflow.add_node(\"retriever\", retriever)\n",
    "workflow.add_node(\"validator\", validator)\n",
    "workflow.add_node(\"strategy_decider\", strategy_decider)\n",
    "\n",
    "workflow.add_edge(START, \"field_selector\")\n",
    "workflow.add_edge(\"field_selector\", \"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"validator\")\n",
    "\n",
    "def check_validation(state):\n",
    "    if state.get(\"retry_count\", 0) >= 3:\n",
    "        return \"pass\"\n",
    "    if state[\"is_valid\"] == \"yes\":\n",
    "        return \"pass\"\n",
    "    return \"fail\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"validator\",\n",
    "    check_validation,\n",
    "    {\n",
    "        \"pass\": END,\n",
    "        \"fail\": \"strategy_decider\"\n",
    "    }\n",
    ")\n",
    "\n",
    "def check_strategy(state):\n",
    "    return state[\"analysis_decision\"]\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"strategy_decider\",\n",
    "    check_strategy,\n",
    "    {\n",
    "        \"rewrite_query\": \"field_selector\",\n",
    "        \"update_fields\": \"retriever\"\n",
    "    }\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a439b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation은 빠져있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc3c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
