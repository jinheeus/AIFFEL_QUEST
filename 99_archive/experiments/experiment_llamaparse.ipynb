{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParse Experiment\n",
    "\n",
    "This notebook experiments with LlamaParse to parse the PDF file `2538-00.pdf` and compare the quality of the output, especially for tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "# !pip install llama-parse llama-index python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAMA_CLOUD_API_KEY found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Check for API Key\n",
    "api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Please set your LLAMA_CLOUD_API_KEY in the .env file or input it below.\")\n",
    "    # api_key = input(\"Enter LLAMA_CLOUD_API_KEY: \")\n",
    "else:\n",
    "    print(\"LLAMA_CLOUD_API_KEY found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=api_key,\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True,\n",
    "    language=\"ko\",  # Set language to Korean\n",
    ")\n",
    "\n",
    "file_path = \"00_data/raw_data/1_bai_raw_files/2538-00.pdf\"\n",
    "documents = parser.load_data(file_path)\n",
    "\n",
    "# Show the first document's text (partial)\n",
    "if documents:\n",
    "    print(f\"Parsed {len(documents)} documents.\")\n",
    "    print(\"First 2000 characters of the parsed content:\")\n",
    "    print(documents[0].text[:2000])\n",
    "else:\n",
    "    print(\"No documents parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to a markdown file for easier inspection\n",
    "output_path = \"2538-00_parsed.md\"\n",
    "if documents:\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(documents[0].text)\n",
    "    print(f\"Saved parsed content to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Now we will process all the PDF files in the directory `00_data/raw_data/1_bai_raw_files/` and save them as markdown files in `00_data/parsed_data/llama_parse/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = \"00_data/raw_data/1_bai_raw_files/\"\n",
    "output_dir = \"00_data/parsed_data/llama_parse/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "# Get list of PDF files\n",
    "pdf_files = glob.glob(os.path.join(input_dir, \"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files.\")\n",
    "\n",
    "# Batch process\n",
    "for pdf_file in tqdm(pdf_files, desc=\"Parsing files\"):\n",
    "    file_name = os.path.basename(pdf_file)\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    output_file = os.path.join(output_dir, f\"{file_base}.md\")\n",
    "\n",
    "    # Skip if already exists\n",
    "    if os.path.exists(output_file):\n",
    "        # print(f\"Skipping {file_name} (already parsed).\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Use aload_data with await to avoid Event loop issues in Jupyter\n",
    "        documents = await parser.aload_data(pdf_file)\n",
    "        if documents:\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(documents[0].text)\n",
    "            # print(f\"Parsed and saved {file_name}\")\n",
    "        else:\n",
    "            print(f\"Warning: No content parsed for {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
