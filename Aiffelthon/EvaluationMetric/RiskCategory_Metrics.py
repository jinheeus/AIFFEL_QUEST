# -*- coding: utf-8 -*-
"""ì„±ëŠ¥í‰ê°€_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KsBrNR7ZygBPBWKzn1LGHIO1uwkXQvHQ

# ì„±ëŠ¥ í‰ê°€ ì§€í‘œ (ìˆ˜ì •íŒ)

## ì‚¬ìš© ì§€í‘œ
1. **ë°©ë²•ë³„ ë¶„ë¥˜ í˜„í™©** - keyword_ai_verified / ai_corrected / ai_direct / keyword_only ë¶„í¬
2. **ì¹´í…Œê³ ë¦¬ ë¶„í¬** - 6ê°œ ì¹´í…Œê³ ë¦¬ ê±´ìˆ˜ ë° ë¹„ìœ¨
3. **í‚¤ì›Œë“œ-AI ì¼ì¹˜ë„** - í‚¤ì›Œë“œê°€ ì œì•ˆí•œ ì¹´í…Œê³ ë¦¬ì™€ AI ìµœì¢… íŒë‹¨ì˜ ì¼ì¹˜ìœ¨
4. **í˜¼ë™ íŒ¨í„´ ë¶„ì„** - AIê°€ í‚¤ì›Œë“œë¥¼ ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ”ì§€
5. **ì‹ ë¢°ë„ ë¶„í¬** - very_high / high / medium / low ë¹„ìœ¨

## ìˆ˜ì • ì´ìœ 
- ROUGE: ai_reasonì´ ì—†ëŠ” keyword_ai_verified(57.5%) ì¼€ì´ìŠ¤ ì œì™¸ë¨ â†’ ë¶ˆê³µì •
- Confidenceë¥¼ ì •í™•ë„ë¡œ ì‚¬ìš©: "í™•ì‹ "â‰ "ì •í™•" â†’ ì˜ë¯¸ì—†ëŠ” ì§€í‘œ
- keyword_suggested ì—†ëŠ” ì¼€ì´ìŠ¤ ëˆ„ë½ â†’ ìˆ˜ì •
"""

import json
import pandas as pd
from collections import Counter

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
HYBRID_FILE = "hybrid_results_20260211_170044.json"
CLASSIFIED_FILE = "data_classified_20260211_170044.json"

# ë°ì´í„° ë¡œë“œ
with open(HYBRID_FILE, 'r', encoding='utf-8') as f:
    hybrid_data = json.load(f)

results = hybrid_data['results']
meta = hybrid_data['metadata']
total = meta['total']

print("=" * 65)
print("ğŸ“Š 1. ë¶„ë¥˜ ë°©ë²•ë³„ í˜„í™©")
print("=" * 65)

method_labels = {
    "keyword_ai_verified": "âœ… í‚¤ì›Œë“œ + AI ì¼ì¹˜",
    "ai_corrected":        "âš ï¸  AIê°€ í‚¤ì›Œë“œ ìˆ˜ì •",
    "ai_direct":           "ğŸ¤– AI ì§ì ‘ ë¶„ë¥˜",
    "keyword_only":        "â— AI ì‹¤íŒ¨ (í‚¤ì›Œë“œë§Œ ì‚¬ìš©)"
}

method_dist = Counter(r.get('method') for r in results)
for method, label in method_labels.items():
    count = method_dist.get(method, 0)
    print(f"  {label:<25}: {count:>5}ê±´ ({count/total*100:>5.1f}%)")

print(f"\n  ì´ê³„: {total}ê±´")
print(f"  ë¹„ìš©: â‚©{meta.get('cost', 0):,.0f}")
print(f"  ì‹œê°„: {meta.get('time_seconds', 0)/3600:.1f}ì‹œê°„")

print("\n" + "=" * 65)
print("ğŸ“Š 2. ì¹´í…Œê³ ë¦¬ ë¶„í¬")
print("=" * 65)

VALID_CATEGORIES = ["ìœ¤ë¦¬/ë¶€íŒ¨/ë¹„ìœ„","ì¸ì‚¬/ì±„ìš©/ë³µë¬´","ì •ë³´ë³´ì•ˆ/IT","ì‹œì„¤/ì•ˆì „/í™˜ê²½","ì¬ë¬´/íšŒê³„/ê³„ì•½","ì‚¬ì—…/ìš´ì˜/ì„±ê³¼"]
cat_dist = Counter(r.get('category') for r in results)

for cat in VALID_CATEGORIES:
    count = cat_dist.get(cat, 0)
    bar = "â–ˆ" * (count * 30 // total)
    print(f"  {cat:<20}: {count:>5}ê±´ ({count/total*100:>5.1f}%) {bar}")

invalid = {k: v for k, v in cat_dist.items() if k not in VALID_CATEGORIES}
if invalid:
    print(f"\nâš ï¸  ì´ìƒê°’: {invalid}")
else:
    print("\nâœ… ì¹´í…Œê³ ë¦¬ ì´ìƒê°’ ì—†ìŒ (6ê°œ ì™„ë²½)")

print("\n" + "=" * 65)
print("ğŸ“Š 3. ì‹ ë¢°ë„ ë¶„í¬")
print("=" * 65)

conf_dist = Counter(r.get('confidence') for r in results)
conf_order = ["very_high", "high", "medium", "low", "very_low"]
for conf in conf_order:
    count = conf_dist.get(conf, 0)
    if count > 0:
        print(f"  {conf:<12}: {count:>5}ê±´ ({count/total*100:>5.1f}%)")

"""## í‚¤ì›Œë“œ-AI ì¼ì¹˜ë„ ë¶„ì„

`keyword_ai_verified`: í‚¤ì›Œë“œì™€ AIê°€ ê°™ì€ ì¹´í…Œê³ ë¦¬ â†’ í•´ë‹¹ í‚¤ì›Œë“œì˜ **ì •í™•ë„ ì¦ê±°**  
`ai_corrected`: AIê°€ í‚¤ì›Œë“œì™€ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì • â†’ **í‚¤ì›Œë“œì˜ í•œê³„** ë“œëŸ¬ë‚¨

### ìˆ˜ì • í¬ì¸íŠ¸
- ê¸°ì¡´: `keyword_suggested` í•„ë“œë§Œ ë´„ â†’ `keyword_ai_verified` 2,853ê±´ ëˆ„ë½
- ìˆ˜ì •: `keyword` í•„ë“œë¡œ í†µí•© ë¶„ì„ (ëª¨ë“  í‚¤ì›Œë“œ ë§¤ì¹­ ì¼€ì´ìŠ¤ í¬í•¨)

"""

import json
import pandas as pd
from collections import defaultdict

with open("hybrid_results_20260211_170044.json", 'r', encoding='utf-8') as f:
    hybrid_data = json.load(f)

results = hybrid_data['results']

# í‚¤ì›Œë“œê°€ ì‚¬ìš©ëœ ì¼€ì´ìŠ¤ ì „ì²´ ë¶„ì„
# keyword_ai_verified: keyword == AI â†’ is_match = 1
# ai_corrected: keyword != AI â†’ is_match = 0
# keyword_only: AI ì‹¤íŒ¨ â†’ is_match = None (ì œì™¸)

analysis = []
for r in results:
    method = r.get('method', '')
    keyword = r.get('keyword')
    final_cat = r.get('category')

    if not keyword:
        continue  # ai_directëŠ” í‚¤ì›Œë“œ ì—†ìŒ

    if method == 'keyword_ai_verified':
        # í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ = AI ì¹´í…Œê³ ë¦¬ (ì¼ì¹˜)
        keyword_cat = final_cat  # ë™ì¼í•˜ë¯€ë¡œ
        analysis.append({'keyword': keyword, 'keyword_cat': keyword_cat,
                         'ai_cat': final_cat, 'is_match': 1, 'method': method})

    elif method == 'ai_corrected':
        # keyword_suggested = í‚¤ì›Œë“œ ì›ë˜ ì¹´í…Œê³ ë¦¬
        keyword_cat = r.get('keyword_suggested', '')
        if keyword_cat:
            analysis.append({'keyword': keyword, 'keyword_cat': keyword_cat,
                             'ai_cat': final_cat, 'is_match': 0, 'method': method})

df = pd.DataFrame(analysis)
total_kw = len(df)

print("=" * 65)
print("ğŸ“Š 4. í‚¤ì›Œë“œ-AI ì¼ì¹˜ë„ ë¶„ì„")
print("=" * 65)
print(f"\ní‚¤ì›Œë“œ ë§¤ì¹­ ì¼€ì´ìŠ¤ ì „ì²´: {total_kw}ê±´")
print(f"  ì¼ì¹˜ (keyword_ai_verified): {df['is_match'].sum():.0f}ê±´ ({df['is_match'].mean()*100:.1f}%)")
print(f"  ìˆ˜ì • (ai_corrected):        {(1-df['is_match']).sum():.0f}ê±´ ({(1-df['is_match'].mean())*100:.1f}%)")

print("\n" + "=" * 65)
print("ğŸ“Š 5. ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì‹ ë¢°ë„")
print("=" * 65)
print("(í‚¤ì›Œë“œë¡œ ë¶„ë¥˜í–ˆì„ ë•Œ AIê°€ ë™ì˜í•œ ë¹„ìœ¨)")
print()

perf = df.groupby('keyword_cat')['is_match'].agg(['count','sum','mean'])
perf.columns = ['í‚¤ì›Œë“œ ì‚¬ìš©', 'AI ë™ì˜', 'ì¼ì¹˜ìœ¨']
perf['ì¼ì¹˜ìœ¨(%)'] = (perf['ì¼ì¹˜ìœ¨'] * 100).round(1)
perf = perf.sort_values('ì¼ì¹˜ìœ¨(%)', ascending=False)

for cat, row in perf.iterrows():
    bar = "â–ˆ" * int(row['ì¼ì¹˜ìœ¨(%)']/5)
    print(f"  {cat:<20}: {row['ì¼ì¹˜ìœ¨(%)']:>5.1f}%  ({row['AI ë™ì˜']:.0f}/{row['í‚¤ì›Œë“œ ì‚¬ìš©']:.0f}ê±´) {bar}")

print("\n" + "=" * 65)
print("ğŸ“Š 6. AI ìˆ˜ì • íŒ¨í„´ (í˜¼ë™ í–‰ë ¬)")
print("=" * 65)
print("(í‚¤ì›Œë“œâ†’ì¹´í…Œê³ ë¦¬ Aë¡œ ë¶„ë¥˜í–ˆëŠ”ë° AIê°€ Bë¡œ ë°”ê¾¼ íŒ¨í„´)")
print()

overrides = df[df['is_match'] == 0]
confusion = overrides.groupby(['keyword_cat', 'ai_cat']).size().reset_index(name='ìˆ˜ì •ê±´ìˆ˜')
confusion = confusion.sort_values('ìˆ˜ì •ê±´ìˆ˜', ascending=False)

for _, row in confusion.head(10).iterrows():
    print(f"  [{row['keyword_cat']}] â†’ [{row['ai_cat']}]: {row['ìˆ˜ì •ê±´ìˆ˜']}ê±´")


"""
LLM-as-a-Judge: ë¬¸ë§¥ ì •í•©ì„± ì¸¡ì •

AI íŒì‚¬ê°€ `ai_reason`ì´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì •ì˜ì™€ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ 0~100ì ìœ¼ë¡œ ì±„ì .  
**ì£¼ì˜**: ai_reasonì´ ì—†ëŠ” `keyword_ai_verified` ì¼€ì´ìŠ¤ëŠ” ì œì™¸ë¨ (ai_corrected, ai_directë§Œ í‰ê°€)
"""


import json
import time
import os
import re
import random  # â† ì¶”ê°€!
from langchain_community.chat_models import ChatClovaX
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

# 1. .env íŒŒì¼ ë¡œë“œ
load_dotenv()
CLOVA_API_KEY = os.getenv("CLOVASTUDIO_API_KEY")

print("\n" + "=" * 65)
print("ğŸ“Š 7. LLM-as-a-Judge: ë¬¸ë§¥ ì •í•©ì„± ì¸¡ì •")
print("=" * 65)

# ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORY_DEFINITIONS = {
    "ìœ¤ë¦¬/ë¶€íŒ¨/ë¹„ìœ„": "ê¸ˆí’ˆìˆ˜ìˆ˜, ë‡Œë¬¼, íš¡ë ¹, ë¹„ë¦¬, ì²­íƒ, ê°‘ì§ˆ ë“± ê³µì§ê¸°ê°• ë° ë¶€íŒ¨ ê´€ë ¨ ì‚¬ì•ˆ",
    "ì¸ì‚¬/ì±„ìš©/ë³µë¬´": "ì±„ìš© ë¶€ì •, ì¸ì‚¬ ë¶ˆê³µì •, ê·¼íƒœ ê´€ë¦¬, ì„±í¬ë¡±, ì¶œì¥ ë° ë³µë¬´ ê·œì • ìœ„ë°˜",
    "ì •ë³´ë³´ì•ˆ/IT": "ê°œì¸ì •ë³´ ìœ ì¶œ, ë³´ì•ˆ ìœ„ë°˜, ì‹œìŠ¤í…œ ì¥ì•  ë° IT ìì‚° ê´€ë¦¬ ë¶€ì ì •",
    "ì‹œì„¤/ì•ˆì „/í™˜ê²½": "ì•ˆì „ì‚¬ê³ , ì‹œì„¤ ê²°í•¨, ë¶€ì‹¤ ì‹œê³µ, ì¬ë‚œ ì˜ˆë°© ë° í™˜ê²½ì˜¤ì—¼ ê´€ë ¨ ì‚¬ì•ˆ",
    "ì¬ë¬´/íšŒê³„/ê³„ì•½": "ì˜ˆì‚°/íšŒê³„ ì˜¤ë¥˜, ê³„ì•½ ìœ„ë°˜, ì •ì‚° ëˆ„ë½, ë¹„ìš© ë° ê¸ˆì•¡ ì‚°ì • ë¶€ì ì •",
    "ì‚¬ì—…/ìš´ì˜/ì„±ê³¼": "ì—…ë¬´ ì§€ì—°, ì§€ì¹¨ ë¯¸ì¤€ìˆ˜, ê´€ë¦¬ ì†Œí™€, ì‚¬ì—… í‰ê°€ ë° ì„±ê³¼ ê´€ë¦¬ ë¶€ì ì •"
}


def evaluate_semantic_alignment(file_path, sample_size=50):
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(file_path):
        print(f"âŒ ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # JSON êµ¬ì¡° ëŒ€ì‘
    items = data.get('results', data)

    # ai_reasonì´ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
    items_with_reason = [r for r in items if r.get('ai_reason', '').strip()]
    
    # [ìˆ˜ì •] ëœë¤ ìƒ˜í”Œë§ (ì¬í˜„ì„±ì„ ìœ„í•´ seed ê³ ì •)
    random.seed(42)
    if len(items_with_reason) > sample_size:
        sample = random.sample(items_with_reason, sample_size)
        print(f"ğŸ“Œ {len(items_with_reason)}ê±´ ì¤‘ ëœë¤ {sample_size}ê±´ ìƒ˜í”Œë§")
    else:
        sample = items_with_reason
        print(f"ğŸ’¡ ai_reasonì´ ìˆëŠ” ë°ì´í„°ê°€ {len(items_with_reason)}ê±´ì´ë¯€ë¡œ ì „ì²´ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.")
        
    if not CLOVA_API_KEY:
        print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì—ì„œ CLOVASTUDIO_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ChatClovaX ì„¤ì •
    chat = ChatClovaX(
        model="HCX-003",
        ncp_clovastudio_api_key=CLOVA_API_KEY,
        temperature=0.1
    )

    scores = []
    print(f"âš–ï¸  AI íŒì‚¬ í‰ê°€ ì¤‘ (ìƒ˜í”Œ {len(sample)}ê±´)...\n")

    for i, item in enumerate(sample, 1):
        cat = item.get('category', '')
        reason = item.get('ai_reason', '')
        definition = CATEGORY_DEFINITIONS.get(cat, "ì •ì˜ ì—†ìŒ")

        prompt = f"""ê°ì‚¬ ê²°ê³¼ ë¶„ë¥˜ì˜ íƒ€ë‹¹ì„±ì„ ê²€í† í•˜ì„¸ìš”.
[ì¹´í…Œê³ ë¦¬ëª…]: {cat}
[ì¹´í…Œê³ ë¦¬ ì •ì˜]: {definition}
[AI ë¶„ë¥˜ ê·¼ê±°]: {reason}

0~100ì ìœ¼ë¡œ ì±„ì í•˜ê³  JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
í˜•ì‹: {{"score": ì ìˆ˜, "reason": "ì´ìœ "}}"""

        try:
            resp = chat.invoke([HumanMessage(content=prompt)])
            # JSON ì¶”ì¶œ
            match = re.search(r'\{.*\}', resp.content, re.DOTALL)
            if match:
                result = json.loads(match.group())
                score = result.get('score', 0)
                scores.append(score)
                print(f"  [{i:02d}/{len(sample)}] idx {item.get('idx')}: {score}ì  - {result.get('reason','')[:40]}")
            
            time.sleep(1.2)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
            
        except Exception as e:
            print(f"  [{i:02d}/{len(sample)}] idx {item.get('idx')} ì˜¤ë¥˜: {e}")
            continue

    # ìµœì¢… ê²°ê³¼ í†µê³„ ì¶œë ¥
    if scores:
        print(f"\n  í‰ê°€ ê±´ìˆ˜: {len(scores)}ê±´ (ai_reason ìˆëŠ” ì¼€ì´ìŠ¤)")
        print(f"  í‰ê·  ì •í•©ì„± ì ìˆ˜: {sum(scores)/len(scores):.1f}ì  / 100ì ")
        print(f"  80ì  ì´ìƒ: {sum(1 for s in scores if s >= 80)}ê±´ ({sum(1 for s in scores if s >= 80)/len(scores)*100:.1f}%)")
        print(f"  60ì  ë¯¸ë§Œ: {sum(1 for s in scores if s < 60)}ê±´ ({sum(1 for s in scores if s < 60)/len(scores)*100:.1f}%)")
        print("=" * 65)
    else:
        print("\nâŒ í‰ê°€ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì‹¤í–‰
if __name__ == "__main__":
    evaluate_semantic_alignment("hybrid_results_20260211_170044.json", sample_size=50)