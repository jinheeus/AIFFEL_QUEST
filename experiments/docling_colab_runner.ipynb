{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling PDF Parser (GPU Accelerated)\n",
    "\n",
    "This notebook is designed to run on Google Colab (T4 GPU) to fast-track the parsing of ALIO and BAI PDF files.\n",
    "\n",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling --quiet\n",
    "!pip install pdf2image --quiet # Optional fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive (Optional) or Upload Data\n",
    "If your data is in Google Drive, mount it. Otherwise, upload a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Uncomment if using Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Define your raw data path here\n",
    "# Example: /content/drive/MyDrive/aiffelthon/00_data/raw_data\n",
    "INPUT_ROOT = \"/content/00_data/raw_data\"\n",
    "OUTPUT_ROOT = \"/content/00_data/parsed_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Parsing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "def run_docling_batch(input_dir, output_dir, dataset_name=\"dataset\"):\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory not found: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    pdf_files = glob.glob(os.path.join(input_dir, \"**/*.pdf\"), recursive=True)\n",
    "    print(f\"[{dataset_name}] Found {len(pdf_files)} PDF files.\")\n",
    "\n",
    "    # Configure Pipeline for GPU\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.do_table_structure = True\n",
    "    pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE\n",
    "    pipeline_options.accelerator_options.device = \"cuda\" # FORCE CUDA\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    success = 0\n",
    "    errors = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for pdf_path in tqdm(pdf_files, desc=f\"Processing {dataset_name}\"):\n",
    "        try:\n",
    "            # Path logic\n",
    "            rel_path = os.path.relpath(pdf_path, input_dir)\n",
    "            out_subdir = os.path.dirname(rel_path)\n",
    "            out_name = os.path.splitext(os.path.basename(pdf_path))[0] + \".md\"\n",
    "            \n",
    "            full_out_dir = os.path.join(output_dir, out_subdir)\n",
    "            os.makedirs(full_out_dir, exist_ok=True)\n",
    "            out_path = os.path.join(full_out_dir, out_name)\n",
    "\n",
    "            if os.path.exists(out_path) and os.path.getsize(out_path) > 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            # Convert\n",
    "            result = converter.convert(pdf_path)\n",
    "            md = result.document.export_to_markdown()\n",
    "\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            \n",
    "            success += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error: {e}\") # Optional: reduce spam\n",
    "            errors += 1\n",
    "    \n",
    "    print(f\"[{dataset_name}] Done. Success: {success}, Skipped: {skipped}, Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ALIO\n",
    "ALIO_INPUT = os.path.join(INPUT_ROOT, \"1_alio_raw_files\")\n",
    "ALIO_OUTPUT = os.path.join(OUTPUT_ROOT, \"alio_docling\")\n",
    "run_docling_batch(ALIO_INPUT, ALIO_OUTPUT, \"ALIO\")\n",
    "\n",
    "# 2. BAI\n",
    "BAI_INPUT = os.path.join(INPUT_ROOT, \"1_bai_raw_files\")\n",
    "BAI_OUTPUT = os.path.join(OUTPUT_ROOT, \"bai_docling\")\n",
    "run_docling_batch(BAI_INPUT, BAI_OUTPUT, \"BAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Zip Results for Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r parsed_data_docling.zip {OUTPUT_ROOT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
