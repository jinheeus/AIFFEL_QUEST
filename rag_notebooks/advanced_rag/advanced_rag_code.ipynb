{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e844d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gyu/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import TypedDict, List\n",
    "from collections import defaultdict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_naver import ChatClovaX, ClovaXEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "from kiwipiepy import Kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatClovaX(\n",
    "    model=\"HCX-DASH-002\", \n",
    "    max_tokens=1024,\n",
    "    temperature=0,\n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "embeddings = ClovaXEmbeddings(\n",
    "    model=\"bge-m3\",\n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "\n",
    "field_selector_system = \"\"\"\n",
    "당신은 감사 보고서 기반 RAG 시스템을 위한 필드 선택기(Field Selector)입니다.\n",
    "사용자 질문을 읽고 아래 7개의 필드 중 관련 있는 필드를 판단해\n",
    "반드시 [\"outline\", \"problems\", ...] 형태로 출력하세요.\n",
    "\n",
    "중요 규칙:\n",
    "- outline과 problems는 모든 질문에서 항상 기본적으로 포함합니다.\n",
    "- 나머지 필드(title, standards, opinion, criteria, action)는\n",
    "  질문의 의도와 직접 관련이 있을 때만 추가로 포함합니다.\n",
    "- 출력은 중복 없이 소문자 문자열 리스트로만 제공합니다.\n",
    "- 설명하지 말고 리스트만 출력하세요.\n",
    "\n",
    "필드 설명:\n",
    "- title: 사건 제목, 사안명\n",
    "- standards: 법령·규정·기준 관련 질문\n",
    "- outline: 사건의 개요·배경·전체 상황 (항상 포함)\n",
    "- problems: 위반 사항·문제점·부적정 사례 (항상 포함)\n",
    "- opinion: 관계기관 의견·평가·입장\n",
    "- criteria: 향후 내부통제·절차 보완·개선 기준\n",
    "- action: 처분·제재·후속 조치\n",
    "\n",
    "출력 규칙:\n",
    "1. 기본 출력: [\"outline\", \"problems\"]\n",
    "2. 질문에 따라 아래와 같이 추가:\n",
    "   - 규정 위반 / 법령 관련 → \"standards\"\n",
    "   - 기관 입장 / 의견 → \"opinion\"\n",
    "   - 개선 방안 / 내부통제 보완 → \"criteria\"\n",
    "   - 처분 / 제재 / 조치 → \"action\"\n",
    "   - 제목 / 사건명 → \"title\"\n",
    "\n",
    "예시:\n",
    "사용자 질문: \"이 사건에서 어떤 규정이 위반되었는지 알려줘.\"\n",
    "출력: [\"outline\", \"problems\", \"standards\"]\n",
    "\n",
    "사용자 질문: \"감사 결과에서 기관은 어떤 입장을 보였어?\"\n",
    "출력: [\"outline\", \"problems\", \"opinion\"]\n",
    "\n",
    "사용자 질문: \"사건의 배경과 전체적인 진행 과정을 설명해줘.\"\n",
    "출력: [\"outline\", \"problems\"]\n",
    "\n",
    "사용자 질문: \"최종 처분은 무엇이었어?\"\n",
    "출력: [\"outline\", \"problems\", \"action\"]\n",
    "\n",
    "사용자 질문: \"앞으로 내부통제를 어떻게 보완해야 할까?\"\n",
    "출력: [\"outline\", \"problems\", \"criteria\"]\n",
    "\"\"\"\n",
    "\n",
    "field_selector_user = \"\"\"\n",
    "outline과 problems는 모든 질문에서 항상 기본적으로 포함합니다.\n",
    "\n",
    "[Question]\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "field_selector_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", field_selector_system),\n",
    "    (\"human\", field_selector_user)\n",
    "])\n",
    "\n",
    "field_selector_chain = (\n",
    "    field_selector_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb78aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    }
   ],
   "source": [
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text) if token.tag.startswith('N')]\n",
    "\n",
    "def get_documents_from_milvus(vector_db):\n",
    "    collection = vector_db.col\n",
    "    res = collection.query(\n",
    "        expr=\"\", \n",
    "        output_fields=[\"text\", \"idx\"], \n",
    "        limit=16384\n",
    "    )\n",
    "    \n",
    "    docs = []\n",
    "    for item in res:\n",
    "        text = item.get('text')\n",
    "        idx = item.get('idx') \n",
    "        \n",
    "        if text:\n",
    "            docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"idx\": idx} \n",
    "            ))\n",
    "            \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120e4fd",
   "metadata": {},
   "source": [
    "#### Hybrid Retriever Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fc3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualEnsembleRetriever:\n",
    "    def __init__(self, retrievers, weights=None, c=60):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights if weights else [0.5] * len(retrievers)\n",
    "        self.c = c \n",
    "\n",
    "    def invoke(self, query):\n",
    "        results = [r.invoke(query) for r in self.retrievers]\n",
    "        rrf_score = defaultdict(float)\n",
    "        doc_map = {}\n",
    "\n",
    "        for r_idx, docs in enumerate(results):\n",
    "            weight = self.weights[r_idx]\n",
    "            for rank, doc in enumerate(docs):\n",
    "                doc_key = doc.page_content\n",
    "                if doc_key not in doc_map:\n",
    "                    doc_map[doc_key] = doc\n",
    "                \n",
    "                score = weight * (1 / (rank + 1 + self.c))\n",
    "                rrf_score[doc_key] += score\n",
    "\n",
    "        sorted_keys = sorted(rrf_score.keys(), key=lambda k: rrf_score[k], reverse=True)\n",
    "        return [doc_map[k] for k in sorted_keys]\n",
    "\n",
    "def create_hybrid_retriever(vector_db, k=20):\n",
    "    raw_docs = get_documents_from_milvus(vector_db)\n",
    "    vector_retriever = vector_db.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    if not raw_docs:\n",
    "        return vector_retriever\n",
    "        \n",
    "    bm25_retriever = BM25Retriever.from_documents(\n",
    "        raw_docs, \n",
    "        preprocess_func=kiwi_tokenize\n",
    "    )\n",
    "    bm25_retriever.k = k\n",
    "    \n",
    "    return ManualEnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.5, 0.5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed99840",
   "metadata": {},
   "source": [
    "#### Initialize Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"title\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "standards_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"standards\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "outline_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"outline\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "problems_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"problems\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "opinion_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"opinion\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "criteria_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"criteria\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "action_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"https://in03-6919b557b41d797.serverless.gcp-us-west1.cloud.zilliz.com\",   \n",
    "        \"token\": \"\"          \n",
    "    },\n",
    "    collection_name=\"action\",                   \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "retrievers = {\n",
    "    \"title\": create_hybrid_retriever(title_db),\n",
    "    \"standards\": create_hybrid_retriever(standards_db),\n",
    "    \"outline\": create_hybrid_retriever(outline_db),\n",
    "    \"problems\": create_hybrid_retriever(problems_db),\n",
    "    \"opinion\": create_hybrid_retriever(opinion_db),\n",
    "    \"criteria\": create_hybrid_retriever(criteria_db),\n",
    "    \"action\": create_hybrid_retriever(action_db),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0a8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = CrossEncoder(\"BAAI/bge-reranker-v2-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    selected_fields: List[str]\n",
    "    documents: List[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fc5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selector(state: GraphState) -> dict:\n",
    "    question = state[\"question\"]\n",
    "    result_str = field_selector_chain.invoke({\"question\": question})\n",
    "    cleaned_result = result_str.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    try:\n",
    "        selected_fields_list = json.loads(cleaned_result)\n",
    "    except:\n",
    "        selected_fields_list = [\"outline\", \"problems\"]\n",
    "        \n",
    "    return {\"selected_fields\": selected_fields_list}\n",
    "\n",
    "\n",
    "def retrieve_documents(state: GraphState) -> dict:\n",
    "    question = state[\"question\"]\n",
    "    target_fields = state.get(\"selected_fields\", [])\n",
    "    \n",
    "    selected_retrievers = {\n",
    "        k: RunnableLambda(retrievers[k].invoke) \n",
    "        for k in target_fields if k in retrievers\n",
    "    }\n",
    "    \n",
    "    if not selected_retrievers:\n",
    "        return {\"documents\": []}\n",
    "\n",
    "    results = RunnableParallel(**selected_retrievers).invoke(question)\n",
    "    \n",
    "    flat_docs = []\n",
    "    for field, docs in results.items():\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source_field\"] = field\n",
    "            flat_docs.append(doc)\n",
    "            \n",
    "    return {\"documents\": flat_docs}\n",
    "\n",
    "\n",
    "def merge_documents(state: GraphState) -> dict:\n",
    "    raw_docs = state.get(\"documents\", [])\n",
    "    grouped = defaultdict(list)\n",
    "    \n",
    "    for doc in raw_docs:\n",
    "        idx = doc.metadata.get(\"idx\")\n",
    "        if idx is not None:\n",
    "            grouped[idx].append((doc.metadata.get(\"source_field\", \"UNKNOWN\"), doc.page_content))\n",
    "\n",
    "    merged_docs = []\n",
    "    for idx, items in grouped.items():\n",
    "        items.sort(key=lambda x: x[0])\n",
    "        full_text = \"\\n\\n\".join([f\"[{field.upper()}]\\n{text}\" for field, text in items])\n",
    "        \n",
    "        merged_docs.append(Document(\n",
    "            page_content=full_text,\n",
    "            metadata={\"idx\": idx, \"fields\": [x[0] for x in items]}\n",
    "        ))\n",
    "        \n",
    "    return {\"documents\": merged_docs}\n",
    "\n",
    "\n",
    "def rerank_documents(state: GraphState) -> dict:\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    if not documents:\n",
    "        return {\"documents\": []}\n",
    "        \n",
    "    pairs = [[question, doc.page_content] for doc in documents]\n",
    "    scores = encoder_model.predict(pairs)\n",
    "    \n",
    "    scored_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return {\"documents\": [doc for doc, _ in scored_docs[:5]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"field_selector\", field_selector)\n",
    "workflow.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "workflow.add_node(\"merge_documents\", merge_documents)\n",
    "workflow.add_node(\"rerank_documents\", rerank_documents)\n",
    "\n",
    "workflow.set_entry_point(\"field_selector\")\n",
    "workflow.add_edge(\"field_selector\", \"retrieve_documents\")\n",
    "workflow.add_edge(\"retrieve_documents\", \"merge_documents\")\n",
    "workflow.add_edge(\"merge_documents\", \"rerank_documents\")\n",
    "workflow.add_edge(\"rerank_documents\", END)\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37afc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation은 빠져있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bb821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
