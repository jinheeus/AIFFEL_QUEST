import sys
import os
import json
import asyncio
from typing import AsyncGenerator

# Add parent directory to path to import agentic_rag_v2 modules
current_dir = os.path.dirname(os.path.abspath(__file__))
# web_app/backend -> web_app -> project_root
project_root = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
rag_dir = os.path.join(project_root, "agentic_rag_v2")
sys.path.append(project_root)  # For config.py
sys.path.append(rag_dir)  # For graph.py and modules

# Ensure Environment Variables are loaded (if needed)
from common.config import Config

from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from graph import app as rag_app  # The compiled LangGraph app
from modules.drafting_agent import DraftingAgent

app = FastAPI(title="Agentic RAG API")

# Allow CORS for Next.js
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    print("üîπ [Startup] Warming up VectorRetriever (Loading BM25 Index)...")
    # Initialize singleton to trigger BM25 build/load
    from modules.vector_retriever import get_retriever

    get_retriever()
    print("üîπ [Startup] VectorRetriever Ready!")


class ChatRequest(BaseModel):
    query: str
    # persona field removed
    history: list = []  # (New) history input
    session_id: str = "default_session"  # New: for persistent memory
    additional_info: dict = {}  # New: for report generation inputs


NODE_NAMES = {
    "supervisor": "Í∞êÏÇ¨ Í≥ÑÌöç ÏàòÎ¶Ω (Supervisor)",
    "chat_worker": "ÏùºÏÉÅ ÎåÄÌôî Ï≤òÎ¶¨",
    "analyze_query": "ÏßàÎ¨∏ ÏùòÎèÑ Î∂ÑÏÑù",
    "decompose_query": "Î≥µÌï© ÏßàÎ¨∏ Î∂ÑÌï¥ Î∞è Í≥ÑÌöç ÏàòÎ¶Ω",
    "retrieve_documents": "Í∑úÏ†ï Î∞è ÏÇ¨Î°Ä Í≤ÄÏÉâ",
    "grade_documents": "Î¨∏ÏÑú Ï†ÅÌï©ÏÑ± ÌèâÍ∞Ä (Adaptive)",
    "rewrite_query": "ÏßàÎ¨∏ Ïû¨ÏûëÏÑ± (Rewrite)",
    "retrieve_graph_context": "Í¥ÄÎ†® Í∑úÏ†ï Ïó∞Í≤∞ Í¥ÄÍ≥Ñ Î∂ÑÏÑù",
    "analyze_stats": "ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞ ÏßëÍ≥Ñ Î∞è Î∂ÑÏÑù",
    "extract_facts": "ÌïµÏã¨ ÏÇ¨Ïã§Í¥ÄÍ≥Ñ Ï∂îÏ∂ú",
    "match_regulations": "Ï†ÅÏö© Î≤ïÎ†π Í≤ÄÌÜ†",
    "evaluate_compliance": "ÏúÑÎ∞ò Ïó¨Î∂Ä ÌåêÏ†ï",
    "determine_disposition": "Ï≤òÎ∂Ñ Í∏∞Ï§Ä Í≤ÄÌÜ†",
    "defense_agent": "ÏÜåÎ™Ö ÎÖºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò",
    "prosecution_agent": "Í∞êÏÇ¨ Ï∑®ÏïΩÏ†ê Ï†êÍ≤Ä",
    "judge_verdict": "ÏµúÏ¢Ö ÌåêÎã® ÎèÑÏ∂ú",
    "generate": "ÎãµÎ≥Ä ÏÉùÏÑ±",
    "generate_answer": "ÎãµÎ≥Ä ÏÉùÏÑ±",
    "reflect_answer": "ÎãµÎ≥Ä Ï†ïÌï©ÏÑ± Í≤ÄÏ¶ù",
}


async def event_generator(
    query: str, history: list, session_id: str
) -> AsyncGenerator[str, None]:
    """
    Yields Server-Sent Events (SSE) for the frontend.
    """
    inputs = {
        "query": query,
        # persona field removed
        # Do NOT initialize documents=[], or it wipes previous state before Router can save it!
        # "documents": [],
        "messages": history,  # Pass history to graph state
        "reflection_count": 0,
    }

    # Thread Config for Redis Memory
    config = {"configurable": {"thread_id": session_id}}

    # Initial Event
    yield f"data: {json.dumps({'type': 'status', 'content': 'Î∂ÑÏÑù ÏãúÏûë...'})}\n\n"

    try:
        # Use astream to get async node updates
        # [Fix] Increase recursion limit for complex RAG flows
        config["recursion_limit"] = 50
        async for output in rag_app.astream(inputs, config=config):
            for key, value in output.items():
                print(f"[API Log] Node Completed: {key}")

                # 1. Send Status Update (Thought Process)
                status_msg = NODE_NAMES.get(key, f"{key} Îã®Í≥Ñ ÏôÑÎ£å")
                yield f"data: {json.dumps({'type': 'status', 'node': key, 'content': status_msg})}\n\n"

                # 2. If Final Answer is ready
                # We need to capture the answer from any node that produces a final output.
                # - 'generate_answer' / 'reflect_answer' (Standard RAG)
                # - 'judge_verdict' (Adversarial Audit)
                # - 'determine_disposition' (SOP - No Violation case)
                final_answer_nodes = [
                    "chat_worker",
                    "generate",
                    "generate_answer",
                    "reflect_answer",
                    "judge_verdict",
                    "determine_disposition",
                    "report_manager",  # Added
                ]

                if key in final_answer_nodes:
                    if "answer" in value and value["answer"]:
                        yield f"data: {json.dumps({'type': 'answer', 'content': value['answer']})}\n\n"

                    # [New] Command Handling (e.g., Open Report)
                    if "command" in value and value["command"]:
                        yield f"data: {json.dumps({'type': 'command', 'content': value['command']})}\n\n"

        yield "data: [DONE]\n\n"

    except Exception as e:
        import traceback

        traceback.print_exc()
        print(f"Error: {e}")
        yield f"data: {json.dumps({'type': 'error', 'content': str(e)})}\n\n"


@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    print(f" -> [API] Incoming Session ID: {request.session_id}")

    # [DEBUG] Session ID
    session_id = request.session_id or "default_session"
    print(f" -> [API] Session ID: {session_id}")

    return StreamingResponse(
        event_generator(request.query, request.history, session_id),
        media_type="text/event-stream",
    )


@app.post("/check_report_readiness")
async def check_report_readiness_endpoint(request: ChatRequest):
    """
    Checks if there is enough information to generate a report.
    """
    print(f"üîπ [API] Checking Readiness for Session: {request.session_id}")
    agent = DraftingAgent()
    result = agent.analyze_requirements(request.history)
    return result


@app.post("/generate_report")
async def generate_report_endpoint(request: ChatRequest):
    """
    Generates a formal audit report based on conversation history.
    """
    print(f"üîπ [API] Generating Report for Session: {request.session_id}")
    print(f"   -> Additional Info: {request.additional_info}")

    # 1. Initialize Components
    agent = DraftingAgent()
    from modules.vector_retriever import get_retriever

    retriever = get_retriever()

    # 2. Construct Search Query for Context (Source B)
    # Priority: Additional Info > Last User Message
    search_query = ""
    if request.additional_info:
        # Combine key fields
        subjects = [
            request.additional_info.get("ÎåÄÏÉÅ Í∏∞Í¥Ä", ""),
            request.additional_info.get("ÏÇ¨Í±¥ Ï†úÎ™©", ""),
            request.additional_info.get("Î¨∏Ï†úÏ†ê", ""),
        ]
        search_query = " ".join([s for s in subjects if s]).strip()

    if not search_query and request.history:
        # Fallback to last user message
        for msg in reversed(request.history):
            if msg["role"] == "user":
                search_query = msg["content"]
                break

    if not search_query:
        search_query = "Í∞êÏÇ¨ Î≥¥Í≥†ÏÑú ÏûëÏÑ± ÏùºÎ∞ò Í∑úÏ†ï"

    print(f"   -> Retrieval Query: '{search_query}'")

    # 3. Retrieve Documents (Source B)
    try:
        retrieved_docs = retriever.search_and_merge(search_query, top_k=3)
        print(f"   -> Retrieved {len(retrieved_docs)} documents for context.")
    except Exception as e:
        print(f"   -> ‚ö†Ô∏è Retrieval Failed: {e}")
        retrieved_docs = []

    # 4. Generate Report
    report_content = agent.generate_report(
        messages=request.history,
        retrieved_docs=retrieved_docs,
        additional_info=request.additional_info,
    )

    # Streaming response (simulating stream for UI consistency, or just text)
    # Using simple text response for now as it's a single block generation
    return {"report": report_content}


@app.get("/health")
def health_check():
    return {"status": "ok", "model": Config.LLM_MODEL}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
