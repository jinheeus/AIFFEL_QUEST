{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline with LangChain (v2 - Zilliz Vector Store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# LangChain components\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import Zilliz # FAISS 대신 Zilliz 임포트\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_classic.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API keys loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "try:\n",
    "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    zilliz_uri = os.getenv(\"ZILLIZ_CLOUD_URI\")\n",
    "    zilliz_token = os.getenv(\"ZILLIZ_CLOUD_TOKEN\")\n",
    "\n",
    "    if not google_api_key: \n",
    "        raise ValueError(\"GOOGLE_API_KEY not set in .env file.\")\n",
    "    if not zilliz_uri:\n",
    "        raise ValueError(\"ZILLIZ_CLOUD_URI not set in .env file.\")\n",
    "    if not zilliz_token:\n",
    "        raise ValueError(\"ZILLIZ_CLOUD_TOKEN not set in .env file.\")\n",
    "    print(\"API keys loaded successfully.\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Document Preparation\n",
    "Load the audit cases and prepare them in LangChain's `Document` format. We create two sets of documents for our hybrid search strategy:\n",
    "1.  **Summary-based documents:** For semantic search (Zilliz).\n",
    "2.  **Keyword-focused documents:** For keyword search (BM25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from audit_cases.json and creating baseline documents from summaries...\n",
      "  - Created 4961 summary-based documents for baseline.\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_docs(filepath=\"audit_cases.json\"):\n",
    "    \"\"\"\n",
    "    'contents_summary' 필드만을 사용하여 문서를 생성\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {filepath} and creating baseline documents from summaries...\")\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        audit_cases = json.load(f)\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for i, case in enumerate(audit_cases):\n",
    "        # 1. 메타데이터 추출\n",
    "        site = case.get('site', '알 수 없음')\n",
    "        category = case.get('category', '알 수 없음')\n",
    "        date = case.get('date', '알 수 없음')\n",
    "        original_title = case.get('title', '')\n",
    "\n",
    "        metadata = {\n",
    "            \"index\": i, \"title\": original_title, \"site\": site,\n",
    "            \"category\": category, \"date\": date\n",
    "        }\n",
    "\n",
    "        # 2. 'contents_summary'를 기반으로 문서 내용 생성\n",
    "        summary_dict = {}\n",
    "        summary_str = case.get('contents_summary')\n",
    "        if summary_str:\n",
    "            try:\n",
    "                summary_dict = ast.literal_eval(summary_str)\n",
    "            except (ValueError, SyntaxError):\n",
    "                summary_dict = {}\n",
    "\n",
    "        title = summary_dict.get('title_str', original_title)\n",
    "        keywords = \", \".join(summary_dict.get('keyword_list', []))\n",
    "        problems = summary_dict.get('problems_str', '')\n",
    "        action = summary_dict.get('action_str', '')\n",
    "        standards = summary_dict.get('standards_str', '')\n",
    "\n",
    "        summary_based_text = (\n",
    "            f\"출처: {site}\\n\"\n",
    "            f\"분류: {category}\\n\"\n",
    "            f\"일자: {date}\\n\"\n",
    "            f\"제목: {title}\\n\"\n",
    "            f\"핵심 키워드: {keywords}\\n\"\n",
    "            f\"문제 요약: {problems}\\n\"\n",
    "            f\"조치 요약: {action}\\n\"\n",
    "            f\"관련 규정: {standards}\"\n",
    "        )\n",
    "\n",
    "        docs.append(Document(page_content=summary_based_text, metadata=metadata))\n",
    "\n",
    "    full_text_documents = docs\n",
    "    keyword_documents = docs\n",
    "\n",
    "    print(f\"  - Created {len(docs)} summary-based documents for baseline.\")\n",
    "    return full_text_documents, keyword_documents\n",
    "\n",
    "full_text_documents, keyword_documents = load_and_prepare_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retriever Setup (Hybrid Search)\n",
    "We'll set up two retrievers and combine them using `EnsembleRetriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models and retrievers...\n",
      "  - Loading Zilliz vector store...\n",
      "    - Zilliz retriever ready.\n",
      "  - Building BM25 index...\n",
      "    - BM25 retriever ready.\n",
      "Ensemble retriever ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize models and tokenizers\n",
    "print(\"Initializing models and retrievers...\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "okt = Okt()\n",
    "\n",
    "# 1. Zilliz (Semantic) Retriever\n",
    "print(\"  - Loading Zilliz vector store...\")\n",
    "zilliz_vectorstore = Zilliz(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"audit_cases_gemma_v1\", # Zilliz에 업로드한 컬렉션 이름\n",
    "    connection_args={\"uri\": zilliz_uri, \"token\": zilliz_token}\n",
    ")\n",
    "semantic_retriever = zilliz_vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"    - Zilliz retriever ready.\")\n",
    "\n",
    "# 2. BM25 (Keyword) Retriever\n",
    "print(\"  - Building BM25 index...\")\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=keyword_documents, \n",
    "    preprocess_func=lambda s: okt.morphs(s) # Use Okt for tokenization\n",
    ")\n",
    "bm25_retriever.k = 5\n",
    "print(\"    - BM25 retriever ready.\")\n",
    "\n",
    "# 3. Ensemble (Hybrid) Retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[semantic_retriever, bm25_retriever],\n",
    "    weights=[0.5, 0.5] # Give equal weight to semantic and keyword search\n",
    ")\n",
    "print(\"Ensemble retriever ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG Chain Construction (LCEL)\n",
    "Now we define the full RAG chain using LangChain Expression Language (LCEL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain constructed successfully.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "당신은 감사 전문가입니다. 제공되는 '관련 감사 사례'를 근거로 하여 사용자의 '질문'에 대해 답변해 주세요. 근거가 부족하면 '정보 없음'으로 답하세요.\n",
    "\n",
    "[관련 감사 사례]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "# Helper function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"### 감사사례 (제목: {doc.metadata.get('title', 'N/A')}){doc.page_content}\" for doc in docs])\n",
    "\n",
    "# RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG chain constructed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Queries\n",
    "**이 셀의 `test_query` 변수만 변경하고 이 셀만 반복적으로 실행하여 다양한 질문을 테스트할 수 있습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running RAG chain for query: '부실시공에 따라 재시공을 하도록 한 감사건도 있나?' ---\n",
      "제공된 감사 사례 중 부실시공에 따라 재시공 또는 이에 준하는 보강 조치를 하도록 한 감사 건은 다음과 같습니다.\n",
      "\n",
      "1.  **2023년도 부산경남본부 종합감사 결과 (제목: 교량내진보강공사 시공 관리 부적정)**\n",
      "    *   **문제 요약:** 철근 배근이 설계도면보다 부족하게 시공되거나, 유압잭 지압응력 검토 없이 시공되는 등 부실 시공이 발생했습니다.\n",
      "    *   **조치 요약:** \"설계 도면과 다르게 시공한 부분에 대해 **보강 조치 실시**\" 및 \"손상 및 균열이 발생한 교량 부재에 대한 안전성 검토 및 **보수 조치**\"를 요구했습니다.\n",
      "\n",
      "2.  **국가철도공단 정기감사 (제목: 경부선 교 교량개량공사 설계 및 시공 부적정)**\n",
      "    *   **문제 요약:** 설계사가 거더 솟음량을 부족하게 설계하고, 시공사가 이를 확인하고도 적절한 조치를 하지 않아 솟음량 부족으로 **보강공사가 요구**되었습니다.\n",
      "    *   **조치 요약:** \"적정한 대책을 마련하여 **보강공사를 시행**해야 함\"을 요구했습니다.\n",
      "\n",
      "3.  **감사위원회 감사보고서(b) (제목: 발코니 출입문 설계 변경 검토 소홀)**\n",
      "    *   **문제 요약:** 발코니 출입문 유효 폭이 좁아 세탁기 반입에 문제가 발생했으며, 이는 수급인이 설계 도면과 다르게 시공한 **시공 상 하자**에 해당했습니다. 공사가 부담하지 않아도 될 **재시공 공사비**가 설계 변경으로 잘못 지급되었습니다.\n",
      "    *   **조치 요약:** \"설계 변경으로 수급인에게 지급한 공사비에 대해 **회수 방안을 마련**\"하도록 요구했습니다. (문제 요약에서 '재시공 공사비'가 언급되어 부실시공에 따른 재시공이 있었음을 알 수 있습니다.)\n",
      "\n",
      "4.  **2024년도 특정감사결과_14 (제목: 연약 지반 통로 박스 신축 이음 부분 이격에 따른 시공 관리 부적정)**\n",
      "    *   **문제 요약:** 연약 지반 내 통로박스의 신축이음부에서 이격 현상이 발생하여 시공 및 건설 사업 관리 업무의 부적정이 확인되었습니다.\n",
      "    *   **조치 요약:** \"신축이음부 이격 원인 규명 및 **보강 대책을 준비하여 조속히 시행**\"하도록 요구했습니다.--- Execution Complete ---\n"
     ]
    }
   ],
   "source": [
    "test_query = \"부실시공에 따라 재시공을 하도록 한 감사건도 있나?\" # 여기에 질문을 변경하세요!\n",
    "\n",
    "print(f\"--- Running RAG chain for query: '{test_query}' ---\")\n",
    "\n",
    "# Invoke the chain and stream the results\n",
    "for chunk in rag_chain.stream(test_query):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"--- Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
